The tools, processes and procedures allowing an organization to create, manipulate, and manage very large data sets and storage facilities.
允许组织去创建，操作和管理巨量数据集和存储设施的工具过程和程序。

因此从广义上来说，大数据只是一个抽象的概念，它包括了巨量数据本身以及处理它所需要的工具、过程和程序。从陕义上说，大数据是各种来源结构化和非结构化的数据集合，通常这种数据集合造成传统软件在可接受的时间内进行数据处理的能力。

* Volumn：数据量大，包括采集、存储和计算量非常大。
* Variety：种类和来源多样性，包括结构化、半结构化和非结构化数据，具体表现为网络日志、音频、视频、图片、地理位置等，多类型的数据对数据的处理能力。
* Value：数据价值密码相对较低，信息感知无处不在，信息海量，但价值密度低，如何结合业务逻辑并通过机器算法来挖掘数据价值。
* Velocity：数据增长速度快，处理速度快，时效要求高。
* Veracity：数据的准确性和可信赖度，即数据的质量。



#### HDFS
HDFS全称Hadoop Distributed File System，叫做Hadoop分布式文件系统，它是Hadoop生态系统最重要的组件。HDFS是Hadoop的主要存储系统。是基于java的文件系统，可为大数据提供可伸缩、容错、可靠、经济、高效的数据存储。HDFS是在商用硬件上运行的分布式文件系统，它支持通过类似shell命令直接交互。HDFS内部最重要的给件是NameNode和DataNode。
* NameNode：不存储实际的数据而是对文件系统内的元素数据进行管理，比如数据块信息、数据分布的存放节点和位置。在同一个集群中，此组件只能有一个处于工作的状态。

* DataNode：负责在HDFS中存储实际数据，DataNode根据客户端的请求执行读取写入操作，DataNode的副本块由文件系统上的两个文件组成，第一个文件用于数，第二个文件用于记录块的元数据。在启动时，每个DataNode连接到其相应的NameNode并进行握手。命名空间ID和DataNode的软件版本的验证通过握手进行，发现不匹配时DataNode自动关闭，DataNode根据NameNode的指令执行诸如块副本创建、删除、复制等操作。

#### Mapreduce
hadoop mapreduce是提供数据处理的核心生态系统组件。mapreduce是一个大数据计算框架，用于处理hadoop分布式文件系统中存储的大量结构化和非结构化数据的计算服务程序。mapreduce程序本质上是并行的，因此对于使用集群中的多台计算机执行大规模数据分析非常有用。因此它提高了集群并行处理的速度和可靠性。    
mapreduce中有两个阶段，分别是map和reduce创段，每个阶段都是有键值对作为输入和输出。map函数获取一组数据并将其转换成另一组数据，其中元素分解为元组，reduce函数将map的输出作为输入，并根据键组合这些数据元组，并相应地修改键的值。该框架拥有运行处理PB级数据的能力，以及快速、容错性等特点，是hadoop生态圈中重要的技术框架。

#### YARN
Yet Another Resource Negotiator提供资源管理的Hadoop生态系统组件，yarn也是hadoop生态系统中重要的组件之一，被称为hadoop的操作系统，因为它负责管理监视工作负载，允许多个数据处理引擎，处理存储在单个平台上的数据。 
yarn具有灵活性特点，除了可以用于批处理计算框架，比如mapreduce外，还可以用于其它模式的数据处理。

#### Zookeeper
zookeeper是hadoop生态系统的重要组件，提供了分布式应用程序协调服务，它是一个为分布式应用提供一致性服务的软件，包括配置维护、域名服务、分布式同频、组服务等。
* 顺序一致性：从同一个客户端发起的事务请求，最终将公严格地按照发起顺序被应用到zookeeper中。
* 原子性：所有事务请求的处理结果在整个集群中所有机器上应用性况是一致的。即整个集群要么都成功应用某个事务，要么都没有应用。
* 单一视图：无论客户端连接的是哪个zookeeper服务器，其看到的服务端数据模型都是一致的。
* 可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非另一个事务对其进行了变更。
* 实时性：zookeeper保证在一定时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。

#### Hive
Hive是一个开源数据仓库系统，是一个数据分析框架，其用于查询和分析存储在hadoop文件中的大型数据集，hive具有三个主要功能：数据汇总、查询、分析。hive使用称为HQL语言与sql相似。hql自动将类似sql的查询转换成mapreduce作业，该作业将在hadoop上执行，简而言之，hive就是hadoop上架了一层sql接口。

#### HBase
HBase是一个分布式数据库，旨在将结构化数据存储在可能具有数据十亿列的表中。HBase是基于HDFS构建的可扩展，分布式和NoSQL数据库。HBase提供对HDFS中读取或写入数据的实时访问。

#### HCatalog
HCatalog是hadoop的表和存储的管理层，它支持hadoop生态系统中可用的不同组件，例如mapreduce、hive等。以轻松地从集群读取写入数据。HCatalog是Hive的关键组件。使用户能够以任何格式和结构存储其数据。

#### Avro
Avro是最流行的数据序列化系统，使用序列化服务程序可以将数据序列为文件或消息，它将数据定义和数据存储在一个消息或文件中，使程序可以轻松地动态了解存储在Avro文件或消息中的信息。

#### Thrift
Thrift是一个轻量级，跨语言的远程服务调用框架，最初是由facebook开发，它通过自身的IDL中间语言，并借助代码生成引擎生成各种注流语言的RPC服务端/客户端模版代码。

#### Drill
Drill是一个低延时的分布式海量数据交互查询引擎，使用ANSI SQL兼容语法，支持本地文件、HDFS、HBase等后端存储。

#### Mahou
Mahout提供了一些经典的机器学习算法，旨在帮助开发人员方便快捷的创建智能应用程序。包括了许多实现、聚类、分类、推荐引擎等。

#### Sqoop
Sqoop是一款用于Hadoop和关系型数据库之间数据导入导出的工具。

#### Flume
Flume是一个分布式、可靠、可用的从多种不同的源收集、聚类、移动大量日志数据到数据存储系统，Flume提供对数据进行简单处理，并写到各种数据接受方的能务。Flume提供了从控制台、RPC、文件、tail、日志系统等数源上收集数据的能力，它使用一个简单的可扩展数据模型，该模型可用于在线分析应用程序。

#### Ambari
Ambari是创建、管理、监视hadoop集群。

#### Oozie
Oozie是用于管理hadoop作业的工作流调度程序系统，可以将多个作业依次组合成一个逻辑工作单元。Oozie框架作为框架中心的Yarn完全集成。

#### Spark
Spark是一个基于scala语言编写的分布式计算框架，相对于Mapreduce计算框架，它减少了内存与磁盘IO操作，spark采用了基于内存的运算，将中间数据结果存储在内存中，方便下次计算调用。

#### Elastic Search
Elastic Search是一个基于lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful接口。

#### Kafka
Kafka是一种分布式，基于发布/订阅的消息系统，采用java和scala编写，该平台为处理即时数据提供了统一、高吞吐、低延时的服务。

#### Flink
Flink是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算，并能以内存速度和任意规模进行计算。它需要计算资源来执行应用程序，flink集成了所有常见的集群资源管理器，但也可以作为独立集群运行。



















